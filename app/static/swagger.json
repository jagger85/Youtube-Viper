{
    "openapi": "3.0.0",
    "info": {
        "description": "This API provides an end-to-end solution for processing Youtube videos by extracting their audio, transcribing the audio into text, and sending the transcribed text to a language model for further processing based on user-defined prompts.\n\n
        <b>Workflow Overview:</b>\n
        1. Video Upload: The user uploads a video file via the API.\n
        2. Audio Extraction: The server extracts the audio track from the uploaded video.\n
        3. Transcription: The extracted audio is transcribed into text using a speech-to-text service.\n
        4. Language Model Processing: The transcribed text is sent to a language model (e.g., GPT) along with a user-defined prompt for advanced processing or analysis.\n
        5. Response: The processed output from the language model is returned to the user.\n\n

        <b>Step-by-Step Integration Guide:</b>\n

        1. <u>WebSocket Connection (for Real-time Updates)</u>\n
           - Connect to the WebSocket endpoint at `/echo`\n
           - Upon connection, you'll receive a unique client_id\n
           - Use this client_id for real time updates\n\n
        
        2. <u>Process a Video</u>\n
           - Make a GET request to `/api/speecher`\n
           - Required parameters:\n
             * video_url: Your YouTube video URL\n
           - Optional parameters:\n
             * client_id: The ID received from WebSocket connection\n
             * prompt: Custom instructions for processing the transcript\n\n
        
        3. <u>Receiving Results</u>\n
           - Real-time updates will be sent through the WebSocket connection\n
           - Final results will be returned in the API response\n\n

        <b>Use Cases:</b>\n
        - Generate summaries of video content\n
        - Extract key insights or themes from spoken content\n
        - Perform sentiment analysis on video transcripts\n
        - Answer specific questions about the video's content\n\n

        <b>Environment Setup:</b>\n
        To run the application, you need to set the following environment variables in a `.env` file located in the project root folder:\n\n
        - **REDIS_PASSWORD**: _Password for accessing the Redis instance._\n
        - **MODEL_API_KEY**: _API key for accessing the language model service._\n
        - **MODEL_API_URL**: _URL for the language model API._\n
        - **LLM_MODEL**: _The specific language model to use for processing._","version": "1.0.0","title": "Speecher API",
        "contact": {
            "email": "andresfonsortega@yahoo.es"
        }
    },
    "servers": [
        {
            "url": "/",
            "description": "Local development server"
        }
    ],
    "tags": [
        {
            "name": "Health",
            "description": "Health check endpoints"
        },
        {
            "name": "Speecher",
            "description": "Speech processing endpoints"
        },
        {
            "name": "WebSocket",
            "description": "WebSocket communication endpoints"
        }
    ],
    "paths": {
        "/api/health": {
            "get": {
                "tags": [
                    "Health"
                ],
                "summary": "Health check endpoint",
                "description": "Use this endpoint to check if the service is up and running",
                "operationId": "checkHealth",
                "responses": {
                    "200": {
                        "description": "Service is healthy",
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "object",
                                    "properties": {
                                        "status": {
                                            "type": "string",
                                            "example": "ok"
                                        }
                                    }
                                }
                            }
                        }
                    }
                }
            }
        },
        "/api/speecher": {
            "get": {
                "tags": [
                    "Speecher"
                ],
                "summary": "Process speech in a video",
                "description": "Submit a video URL for speech processing with optional prompt",
                "operationId": "processSpeech",
                "parameters": [
                    {
                        "name": "client_id",
                        "in": "query",
                        "required": false,
                        "description": "Unique client identifier to receive real-time updates through the web socket connection",
                        "schema": {
                            "type": "string"
                        }
                    },
                    {
                        "name": "video_url",
                        "in": "query",
                        "required": true,
                        "description": "Youtube video URL to process",
                        "schema": {
                            "type": "string",
                            "format": "uri"
                        }
                    },
                    {
                        "name": "prompt",
                        "in": "query",
                        "required": false,
                        "description": "Optional prompt for speech processing",
                        "schema": {
                            "type": "string"
                        }
                    },                    {
                        "name": "operation_type",
                        "in": "query",
                        "required": true,
                        "description": "Define if transcribe the audio only or process it with an llm",
                        "schema": {
                            "type": "string"
                        }
                    }
                ],
                "responses": {
                    "200": {
                        "description": "Speech processing completed successfully",
                        "content": {
                            "application/json": {
                                "schema": {
                                    "type": "object",
                                    "properties": {
                                        "result": {
                                            "type": "object",
                                            "description": "Processing result"
                                        }
                                    }
                                }
                            }
                        }
                    },
                    "400": {
                        "description": "Bad request - missing required parameters",
                        "content": {
                            "application/json": {
                                "schema": {
                                    "$ref": "#/components/schemas/Error"
                                },
                                "example": {
                                    "error": "client_id is required"
                                }
                            }
                        }
                    },
                }
            }
        },
        "/echo": {
            "get": {
                "tags": [
                    "WebSocket"
                ],
                "summary": "WebSocket connection endpoint",
                "description": "A WebSocket connection for real-time updates, when connected the server will send the unique client identifier where you can subscribe for real-time processing updates",
                "operationId": "wsConnect",
                "responses": {
                    "101": {
                        "description": "WebSocket connection established"
                    }
                }
            }
        }
    }
}